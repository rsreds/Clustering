{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4297,
     "status": "ok",
     "timestamp": 1559761344443,
     "user": {
      "displayName": "Simone Rossi Tisbeni",
      "photoUrl": "",
      "userId": "06632140500806572497"
     },
     "user_tz": -120
    },
    "id": "R-xnZhPPU7JN",
    "outputId": "3976cf41-1a32-4306-c7c1-d607e48ecfeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4286,
     "status": "ok",
     "timestamp": 1559761344445,
     "user": {
      "displayName": "Simone Rossi Tisbeni",
      "photoUrl": "",
      "userId": "06632140500806572497"
     },
     "user_tz": -120
    },
    "id": "IeBgppBAVH9w",
    "outputId": "8029c344-3d0e-46f3-d01b-41114e7232d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EATEMj2AUzOh"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import getopt\n",
    "from time import time\n",
    "from math import cos, sqrt\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import Levenshtein as lv\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "DEFAULT_MIN_SIM_THRESHOLD = 0.7\n",
    "\n",
    "USER = re.compile('<.*>')\n",
    "REQUEST = re.compile(\n",
    "    '((\\w|\\d){8})-((\\w|\\d){4})-((\\w|\\d){4})-((\\w|\\d){4})-((\\w|\\d){12})')\n",
    "TOKEN = re.compile('\\[token:.*\\]')\n",
    "SURL = re.compile('srm:.+?(?=]| |$)')\n",
    "PATH = re.compile('/.+?(?=]| |$)')\n",
    "\n",
    "\n",
    "def clean_log(log):\n",
    "    '''\n",
    "    Cleans the log file using regex to remove unneccessary data\n",
    "    '''\n",
    "    log = re.sub(USER, 'USER', log)\n",
    "    log = re.sub(TOKEN, 'TOKEN', log)\n",
    "    log = re.sub(REQUEST, 'REQ_ID', log)\n",
    "    log = re.sub(SURL, 'SURL', log)\n",
    "    log = re.sub(PATH, 'PATH', log)\n",
    "    return log\n",
    "\n",
    "\n",
    "def similarity(str1, str2, method='levenshtein'):\n",
    "    if method == 'lenvenshtein':\n",
    "        return lv.seqratio(str1, str2)\n",
    "\n",
    "\n",
    "def clusterize(df, sim_thres=DEFAULT_MIN_SIM_THRESHOLD):\n",
    "    '''\n",
    "    Clusterizes the dataframe based on the similarity of logs to the reference \n",
    "    of each cluster\n",
    "    If no cluster within the threshold is found creates new cluster\n",
    "\n",
    "    Uses normalized Levenshtein distance\n",
    "\n",
    "    Returns the dataframe and a dicionary of clusters\n",
    "    '''\n",
    "    t0 = time()\n",
    "    clusters = []\n",
    "    time_trend = []\n",
    "    id = 0\n",
    "    for row in tqdm(df.itertuples()):\n",
    "        best_clust = None\n",
    "        i = getattr(row, 'Index')\n",
    "        datetime = getattr(row, 'datetime')\n",
    "        log = getattr(row, 'message')\n",
    "        cleaned_log = getattr(row, 'cleaned_message')\n",
    "        if pd.isnull(datetime):\n",
    "            cleaned_log = 'JAVA_ERROR'\n",
    "        if len(clusters) == 0:\n",
    "            clusters.append({'id': id, 'ref': cleaned_log, 'count': 1})\n",
    "            df.at[i, 'cluster'] = id\n",
    "            id = id+1\n",
    "            t = time()-t0\n",
    "            time_trend.append([t, id, i])\n",
    "            continue\n",
    "\n",
    "        similarities = [similarity(cleaned_log, cluster['ref'], 'lenvenshtein')\n",
    "                        for cluster in clusters]\n",
    "        best_clust = np.argmax(similarities)\n",
    "        if similarities[best_clust] > sim_thres:\n",
    "            clusters[best_clust]['count'] = clusters[best_clust]['count']+1\n",
    "            df.at[i, 'cluster'] = clusters[best_clust]['id']\n",
    "        else:\n",
    "            clusters.append({'id': id, 'ref': cleaned_log, 'count': 1})\n",
    "            df.at[i, 'cluster'] = id\n",
    "            id = id+1\n",
    "            t = time() - t0\n",
    "            time_trend.append([t, id, i])\n",
    "\n",
    "    df.cluster = df.cluster.astype(int)\n",
    "    return df, clusters, time_trend\n",
    "\n",
    "\n",
    "def add_value_labels(ax, reference_logs, spacing=5):\n",
    "    '''\n",
    "    Writes the occurrence value over each bar\n",
    "\n",
    "    If reference log list is provided writes the corresponding log over each bar\n",
    "    '''\n",
    "    id = 0\n",
    "    for rect in ax.patches:\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        vert_spacing = spacing\n",
    "        vert_alignment = 'bottom'\n",
    "        angle = 90\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            vert_spacing *= -1\n",
    "            vert_alignment = 'top'\n",
    "\n",
    "        # Create value annotation\n",
    "        label = \"{:.0f}\".format(y_value)\n",
    "        ax.annotate(label, (x_value, y_value), xytext=(0, vert_spacing),\n",
    "                    textcoords=\"offset points\", ha='center', va=vert_alignment)\n",
    "\n",
    "        # Create log annotation\n",
    "        if isinstance(reference_logs, (list,)):\n",
    "            label = reference_logs[id]\n",
    "            ax.annotate(label, (x_value, y_value), xytext=(0, vert_spacing*4),\n",
    "                        textcoords=\"offset points\", ha='center', va=vert_alignment,\n",
    "                        rotation=angle, fontsize='xx-small')\n",
    "        id = id+1\n",
    "\n",
    "\n",
    "def plot_clusters(cluster_array, write_ref=False, skip_single=False):\n",
    "    '''\n",
    "    Plot the cluster size bar graph\n",
    "    If list of label is passed prints it over each bar\n",
    "\n",
    "    Label should be the refernce log for each cluster\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    ids = [row[0] for row in cluster_array]\n",
    "    occurrence = [row[1] for row in cluster_array]\n",
    "\n",
    "    if write_ref is True:\n",
    "        reference_log = [row[2] for row in cluster_array]\n",
    "    else:\n",
    "        reference_log = None\n",
    "\n",
    "    if skip_single == True:\n",
    "        y = occurrence[occurrence > 1]\n",
    "        x = ids[occurrence > 1]\n",
    "    else:\n",
    "        y = occurrence\n",
    "        x = ids\n",
    "\n",
    "    ax.bar(range(len(x)), y)\n",
    "    ax.set_xticks(range(len(x)))\n",
    "    ax.set_xticklabels(x)\n",
    "    ax.set_xlabel('cluster')\n",
    "    ax.set_ylabel('occurrences')\n",
    "\n",
    "    add_value_labels(ax, reference_log)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGOYmnw3UzOl"
   },
   "source": [
    "To run the script run the following code with path to `inputfile` and `outputfile`, and proper `similarity_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "V12BJ5v3UzOm",
    "outputId": "a1be75c3-52f0-4b98-ac24-9b55c6a64555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: 2019-05-25-storm-backend.log.csv\n",
      "Loaded 2996214 lines\n",
      "Cleaning log\n",
      "Logs cleaned, started clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2996214it [1:06:45, 748.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered. Saving to C:/Users/simor/Desktop/output/output/\n",
      "Saved log csv in clustered-2019-05-25-storm-backend.log.csv\n",
      "Saved clusters csv in cluster_table-2019-05-25-storm-backend.log.csv\n",
      "Saved time trend csv in time_trend-2019-05-25-storm-backend.log.csv\n",
      "Loading: 2019-05-26-storm-backend.log.csv\n",
      "Loaded 3117686 lines\n",
      "Cleaning log\n",
      "Logs cleaned, started clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3117686it [56:13, 924.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered. Saving to C:/Users/simor/Desktop/output/output/\n",
      "Saved log csv in clustered-2019-05-26-storm-backend.log.csv\n",
      "Saved clusters csv in cluster_table-2019-05-26-storm-backend.log.csv\n",
      "Saved time trend csv in time_trend-2019-05-26-storm-backend.log.csv\n",
      "Loading: 2019-05-27-storm-backend.log.csv\n",
      "Loaded 4134166 lines\n",
      "Cleaning log\n",
      "Logs cleaned, started clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4134166it [1:56:52, 589.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered. Saving to C:/Users/simor/Desktop/output/output/\n",
      "Saved log csv in clustered-2019-05-27-storm-backend.log.csv\n",
      "Saved clusters csv in cluster_table-2019-05-27-storm-backend.log.csv\n",
      "Saved time trend csv in time_trend-2019-05-27-storm-backend.log.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "inputpath = 'C:/Users/simor/Desktop/output/'\n",
    "outputpath = 'C:/Users/simor/Desktop/output/output/'\n",
    "\n",
    "filelist = ['2019-05-25-storm-backend.log.csv','2019-05-26-storm-backend.log.csv','2019-05-27-storm-backend.log.csv']\n",
    "for filename in filelist:\n",
    "    print('Loading: ' + filename)\n",
    "    inputfile = inputpath + filename\n",
    "    df = pd.read_csv(inputfile)\n",
    "    print('Loaded ' + str(len(df.index)) + ' lines')\n",
    "\n",
    "    print('Cleaning log')\n",
    "    df['cleaned_message'] = df['message'].apply(clean_log)\n",
    "    print('Logs cleaned, started clustering')\n",
    "\n",
    "    df, cluster_dict, time_trend = clusterize(df, DEFAULT_MIN_SIM_THRESHOLD)\n",
    "    \n",
    "    print('Clustered. Saving to ' + outputpath)\n",
    "    df.to_csv(outputpath + 'clustered-' + filename, compression='zip')\n",
    "    \n",
    "    print('Saved log csv in '+ 'clustered-' + filename)\n",
    "    array = [[dic['id'], dic['count'], dic['ref']] for dic in cluster_dict]\n",
    "    np.savetxt(outputpath + 'cluster_table-' + filename,\n",
    "               array, fmt='%s', delimiter=',')\n",
    "    print('Saved clusters csv in '+ 'cluster_table-' + filename)\n",
    "\n",
    "    np.savetxt(outputpath + 'time_trend-' +\n",
    "               filename, time_trend, delimiter=',')\n",
    "    print('Saved time trend csv in '+ 'time_trend-' + filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LL4wm2TyUzOp"
   },
   "source": [
    "To plot the result run the following script, set `reference_logs` to false if you don't want to show the logs label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "st73hJLQUzOq"
   },
   "outputs": [],
   "source": [
    "fig = plot_clusters(array, write_ref=False, skip_single=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cluster Creator.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
